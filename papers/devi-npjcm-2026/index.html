<!DOCTYPE html>
<html lang="en">
	<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Leveraging transfer learning for accurate estimation of ionic migration barriers in solids | Simulations and Informatics of Materials Group</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="Leveraging transfer learning for accurate estimation of ionic migration barriers in solids" />
<meta name="author" content="Sai Gautam Gopalakrishnan" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Abstract Rate performance of several applications, such as batteries, fuel cells, and electrochemical sensors, is exponentially dependent on the ionic migration barrier (Em) within solids, a difficult-to-estimate quantity. Previous approaches to identify materials with low Em have often relied on imprecise descriptors or rules-of-thumb. Here, we present a graph-neural-network-based architecture that leverages principles of transfer learning to efficiently and accurately predict Em across a variety of materials. We use a model (labeled MPT) that has been simultaneously pre-trained on seven bulk properties, introduce architectural modifications to build inductive bias on different migration pathways in a structure, and subsequently fine-tune (FT) on a manually-curated, literature-derived, first-principles computational dataset of 619 Em values. Importantly, our best-performing FT model (labeled MODEL-3, based on test set scores) demonstrates substantially better accuracy compared to classical machine learning methods, graph models trained from scratch, and a universal machine learned interatomic potential, with a R2 score and a mean absolute error of 0.703 ± 0.109 and 0.261 ± 0.034 eV, respectively, on the test set and is able to classify ‘good’ ionic conductors with an 80% accuracy. Thus, our work demonstrates the effective use of FT strategies and MPT architectural modifications to predict Em, and can be extended to make predictions on other data-scarce material properties." />
<meta property="og:description" content="Abstract Rate performance of several applications, such as batteries, fuel cells, and electrochemical sensors, is exponentially dependent on the ionic migration barrier (Em) within solids, a difficult-to-estimate quantity. Previous approaches to identify materials with low Em have often relied on imprecise descriptors or rules-of-thumb. Here, we present a graph-neural-network-based architecture that leverages principles of transfer learning to efficiently and accurately predict Em across a variety of materials. We use a model (labeled MPT) that has been simultaneously pre-trained on seven bulk properties, introduce architectural modifications to build inductive bias on different migration pathways in a structure, and subsequently fine-tune (FT) on a manually-curated, literature-derived, first-principles computational dataset of 619 Em values. Importantly, our best-performing FT model (labeled MODEL-3, based on test set scores) demonstrates substantially better accuracy compared to classical machine learning methods, graph models trained from scratch, and a universal machine learned interatomic potential, with a R2 score and a mean absolute error of 0.703 ± 0.109 and 0.261 ± 0.034 eV, respectively, on the test set and is able to classify ‘good’ ionic conductors with an 80% accuracy. Thus, our work demonstrates the effective use of FT strategies and MPT architectural modifications to predict Em, and can be extended to make predictions on other data-scarce material properties." />
<link rel="canonical" href="http://sai-mat-group.github.io/papers/devi-npjcm-2026/" />
<meta property="og:url" content="http://sai-mat-group.github.io/papers/devi-npjcm-2026/" />
<meta property="og:site_name" content="Simulations and Informatics of Materials Group" />
<meta property="og:image" content="http://sai-mat-group.github.io/images/papers/devi-npjcm-2026.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2026-02-13T00:00:00+05:30" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="http://sai-mat-group.github.io/images/papers/devi-npjcm-2026.png" />
<meta property="twitter:title" content="Leveraging transfer learning for accurate estimation of ionic migration barriers in solids" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Sai Gautam Gopalakrishnan"},"dateModified":"2026-02-13T00:00:00+05:30","datePublished":"2026-02-13T00:00:00+05:30","description":"Abstract Rate performance of several applications, such as batteries, fuel cells, and electrochemical sensors, is exponentially dependent on the ionic migration barrier (Em) within solids, a difficult-to-estimate quantity. Previous approaches to identify materials with low Em have often relied on imprecise descriptors or rules-of-thumb. Here, we present a graph-neural-network-based architecture that leverages principles of transfer learning to efficiently and accurately predict Em across a variety of materials. We use a model (labeled MPT) that has been simultaneously pre-trained on seven bulk properties, introduce architectural modifications to build inductive bias on different migration pathways in a structure, and subsequently fine-tune (FT) on a manually-curated, literature-derived, first-principles computational dataset of 619 Em values. Importantly, our best-performing FT model (labeled MODEL-3, based on test set scores) demonstrates substantially better accuracy compared to classical machine learning methods, graph models trained from scratch, and a universal machine learned interatomic potential, with a R2 score and a mean absolute error of 0.703 ± 0.109 and 0.261 ± 0.034 eV, respectively, on the test set and is able to classify ‘good’ ionic conductors with an 80% accuracy. Thus, our work demonstrates the effective use of FT strategies and MPT architectural modifications to predict Em, and can be extended to make predictions on other data-scarce material properties.","headline":"Leveraging transfer learning for accurate estimation of ionic migration barriers in solids","image":"http://sai-mat-group.github.io/images/papers/devi-npjcm-2026.png","mainEntityOfPage":{"@type":"WebPage","@id":"http://sai-mat-group.github.io/papers/devi-npjcm-2026/"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://sai-mat-group.github.io/images/logo.png"},"name":"Sai Gautam Gopalakrishnan"},"url":"http://sai-mat-group.github.io/papers/devi-npjcm-2026/"}</script>
<!-- End Jekyll SEO tag -->

<head>
	<meta charset="utf-8"/>
	<title>Leveraging transfer learning for accurate estimation of ionic migration barriers in solids</title>
	<meta name="viewport" content="width=device-width, initial-scale=1.0">

	<meta name="google-site-verification" content="zEGG9gOi40Xq8GSeRtDEq17a6MV4LyM44AAc8mE7YxA" />

	<!-- Google tag (gtag.js) -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-9ZRNS1MC6F"></script>
	<script>
  	window.dataLayer = window.dataLayer || [];
  	function gtag(){dataLayer.push(arguments);}
  	gtag('js', new Date());
	
  	gtag('config', 'G-9ZRNS1MC6F');
	</script>

	<!-- Global site tag (gtag.js) - Old Google Analytics -->
	<!--script async src="https://www.googletagmanager.com/gtag/js?id=UA-176100633-1"></script>
	<script>
  	window.dataLayer = window.dataLayer || [];
  	function gtag(){dataLayer.push(arguments);}
  	gtag('js', new Date());

  	gtag('config', 'UA-176100633-1');
	</script-->

	<!-- Google Analytics -->
	<!--script>
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-176100633-1', 'auto');
	ga('send', 'pageview');
	</script>
	<script async src='https://www.google-analytics.com/analytics.js'></script-->
	<!-- End Old Google Analytics -->

	
	<!-- RSS feed -->
	<link rel="alternate" type="application/rss+xml" title="Simulations and Informatics of Materials Group" href="http://sai-mat-group.github.io/feed.xml">
	
    <!-- Customized Bootstrap + Font Awesome + Solarized -->
    <link href="/css/style.css" rel="stylesheet" media="screen">

	<!-- Favicon -->
	<link rel="shortcut icon" href="/images/favicon.png"/>	

	<!-- Ideal image slider -->
	<!-- Jekyll Ideal Image Slider Include -->
<!-- https://github.com/jekylltools/jekyll-ideal-image-slider-include -->
<!-- v1.8 -->


	<!-- Typekit -->
	<script>
	  //(function(d) {
		//var config = {
		  //kitId: 'xeu8jut',
		  //scriptTimeout: 3000
		//},
		//h=d.documentElement,t=setTimeout(function(){h.className=h.className.replace(/\bwf-loading\b/g,"")+" wf-inactive";},config.scriptTimeout),tk=d.createElement("script"),f=false,s=d.getElementsByTagName("script")[0],a;h.className+=" wf-loading";tk.src='//use.typekit.net/'+config.kitId+'.js';tk.async=true;tk.onload=tk.onreadystatechange=function(){a=this.readyState;if(f||a&&a!="complete"&&a!="loaded")return;f=true;clearTimeout(t);try{Typekit.load(config)}catch(e){}};s.parentNode.insertBefore(tk,s)
	  //})(document);
	</script>
			
	<!-- jQuery -->
	<script src="/js/jquery.min.js"></script>

	<!-- Bootstrap -->
	<script src="/js/bootstrap.min.js"></script>
	<!--script src="/js/transition.js"></script>
	<script src="/js/collapse.js"></script-->

</head>

<body>

	<div id="header">
		<nav class="navbar navbar-expand-md navbar">	 
			<div class="container">
				<a class="navbar-brand" href="/">
				<img class="logo navbar-brand d-inline-block align-top ml-0 mr-1" src="/images/logo.svg">
					SAI MATerials Group</a>
				<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
					<span class="navbar-toggler-icon"></span>
				</button>
				<div class="collapse navbar-collapse" id="navbarNav">
					<ul class="navbar-nav nav-pills ml-auto">
						
						<li class="nav-link">
						
						<a class="mx-1" href="/research/">Research</a>
						</li>
						
						<li class="nav-link active">
						
						<a class="mx-1" href="/papers/">Publications</a>
						</li>
						
						<li class="nav-link">
						
						<a class="mx-1" href="/presentations/">Presentations</a>
						</li>
						
						<li class="nav-link">
						
						<a class="mx-1" href="/team/">Team</a></li>	  
						
						<li class="nav-link">
						
						<a class="mx-1" href="/join-us/">Join Us</a>
					</ul>
				</div>
			</div>
		</nav>
	</div>

	<div class="container mt-4">

	<div class="row">
	<div class="col-md-12">
		<div class="media">
			<div class="col-md-3">
			
			<img class="pull-left pad-right media-object" src="/images/papers/devi-npjcm-2026.png">
			
			</div>
			<div class="col-md-9">
			<div class="media-body titlebox">
				<div class="paper-title media-heading">
					Leveraging transfer learning for accurate estimation of ionic migration barriers in solids
				</div>
				<p>
				<div class="smallhead">
					R. Devi, K. T. Butler, and <b>G. Sai Gautam</b>;
					npj Comput. Mater. 12, 88 (2026)
				</div>
			</div>
			</div>
			<!---<div class="col-md-8">
				<div class="post">
					<h1 id="abstract">Abstract</h1>
<p>Rate performance of several applications, such as batteries, fuel cells, and electrochemical sensors, is exponentially dependent on the ionic migration barrier (E<sub>m</sub>) within solids, a difficult-to-estimate quantity. Previous approaches to identify materials with low E<sub>m</sub> have often relied on imprecise descriptors or rules-of-thumb. Here, we present a graph-neural-network-based architecture that leverages principles of transfer learning to efficiently and accurately predict E<sub>m</sub> across a variety of materials. We use a model (labeled MPT) that has been simultaneously pre-trained on seven bulk properties, introduce architectural modifications to build inductive bias on different migration pathways in a structure, and subsequently fine-tune (FT) on a manually-curated, literature-derived, first-principles computational dataset of 619 E<sub>m</sub> values. Importantly, our best-performing FT model (labeled MODEL-3, based on test set scores) demonstrates substantially better accuracy compared to classical machine learning methods, graph models trained from scratch, and a universal machine learned interatomic potential, with a R<sup>2</sup> score and a mean absolute error of 0.703 ± 0.109 and 0.261 ± 0.034 eV, respectively, on the test set and is able to classify ‘good’ ionic conductors with an 80% accuracy. Thus, our work demonstrates the effective use of FT strategies and MPT architectural modifications to predict E<sub>m</sub>, and can be extended to make predictions on other data-scarce material properties.</p>

				</div>
			</div>-->
		</div>	
	</div>
</div>

<div class="bigspacer"></div>

<div class="row">
	<div class="col-md-3">
		<div class="bigspacer"></div>
		<div class="glyphbox note">
			
			<div class="smallhead">
				PDF
			</div>
			<div class="pad-left note">
				<div class="smallspacer"></div>
				<i class="fa fa-file-text-o fa-fw"></i>
				<a class="off" href="/pdfs/papers/devi-npjcm-2026.pdf">devi-npjcm-2026.pdf</a>
			</div>
			<div class="bigspacer"></div>
			
			
			<div class="smallhead">
				Supporting Information
			</div>
			<div class="pad-left note">
				<div class="smallspacer"></div>
				<i class="fa fa-paperclip fa-fw"></i>
				<a class="off" href="/pdfs/papers/devi-npjcm-2026-si.pdf">devi-npjcm-2026-si.pdf</a>
			</div>
			<div class="bigspacer"></div>
			
			
			<div class="smallhead">
				DOI
			</div>
			<div class="pad-left note">
				<div class="smallspacer"></div>
				<i class="ai ai-doi"></i>
				<a class="off" href="https://doi.org/10.1038/s41524-026-01972-8">10.1038/s41524-026-01972-8</a>
			</div>
			<div class="bigspacer"></div>
			
			
			<div class="smallhead">
				GitHub
			</div>
			<div class="pad-left note">
				<div class="smallspacer"></div>
				<i class="fa fa-github-alt fa-fw"></i>
				<a class="off" href="https://github.com/sai-mat-group/predicting-migration-barriers">sai-mat-group/<wbr>predicting-migration-barriers</a>
			</div>
			<div class="bigspacer"></div>
			
			
			<div class="smallhead">
				arXiv
			</div>
			<div class="pad-left note">
				<div class="smallspacer"></div>
				<i class="fa fa-file-archive-o fa-fw"></i>
				<a class="off" href="https://arxiv.org/abs/2508.06436">2508.06436</a>
			</div>
			<div class="bigspacer"></div>
			
			
			
		</div>
	</div>
	<div class="col-md-8">
		<div class="post">
			<h1 id="abstract">Abstract</h1>
<p>Rate performance of several applications, such as batteries, fuel cells, and electrochemical sensors, is exponentially dependent on the ionic migration barrier (E<sub>m</sub>) within solids, a difficult-to-estimate quantity. Previous approaches to identify materials with low E<sub>m</sub> have often relied on imprecise descriptors or rules-of-thumb. Here, we present a graph-neural-network-based architecture that leverages principles of transfer learning to efficiently and accurately predict E<sub>m</sub> across a variety of materials. We use a model (labeled MPT) that has been simultaneously pre-trained on seven bulk properties, introduce architectural modifications to build inductive bias on different migration pathways in a structure, and subsequently fine-tune (FT) on a manually-curated, literature-derived, first-principles computational dataset of 619 E<sub>m</sub> values. Importantly, our best-performing FT model (labeled MODEL-3, based on test set scores) demonstrates substantially better accuracy compared to classical machine learning methods, graph models trained from scratch, and a universal machine learned interatomic potential, with a R<sup>2</sup> score and a mean absolute error of 0.703 ± 0.109 and 0.261 ± 0.034 eV, respectively, on the test set and is able to classify ‘good’ ionic conductors with an 80% accuracy. Thus, our work demonstrates the effective use of FT strategies and MPT architectural modifications to predict E<sub>m</sub>, and can be extended to make predictions on other data-scarce material properties.</p>

		</div>
	</div>
	<div class="col-md-1"></div>
</div>



	</div>

	<div class="spacer"></div>

	<div class="container mt-4">
		<div class="row">
			<div class="col-lg-12 reduced gutter">
				<div class="pad-left">
					<ul class="list-inline">
						<li class="footernav list-inline-item">
							<i class="fa fa-angle-right"></i> <a class="off-footer" href="/news">Group News</a>
						</li>
						
						<li class="footernav list-inline-item">
							<i class="fa fa-angle-right"></i> <a class="off-footer" href="/misc/funders/">Funders</a>
						</li>
						
						<li class="footernav list-inline-item">
							<i class="fa fa-angle-right"></i> <a class="off-footer" href="/misc/contact/">Contact</a>
						</li>
						
						<li class="footernav list-inline-item">
							<i class="fa fa-angle-right"></i> <a class="off-footer" target="_blank" rel="noopener noreferrer" href="https://materials.iisc.ac.in">Materials Engineering</a>
						</li>
						<li class="footernav list-inline-item">
							<i class="fa fa-angle-right"></i> <a class="off-footer" target="_blank" rel="noopener noreferrer" href="https://iisc.ac.in">IISc</a>
						</li>
						<li class="footernav list-inline-item"> <a class="footerimage" href="https://twitter.com/goths19" target="_blank" rel="noopener noreferrer">
							<i class="fa fa-twitter"></i></a>
						</li>
						<li class="footernav list-inline-item"> <a class="footerimage" href="https://linkedin.com/in/sai-gautam-gopalakrishnan" target="_blank" rel="noopener noreferrer">
							<i class="fa fa-brands fa-linkedin"></i></a>
						</li>
						<li class="footernav list-inline-item"> <a class="footerimage" href="https://github.com/sai-mat-group" target="_blank" rel="noopener noreferrer">
							<i class="fa fa-github"></i></a>
						</li>
						<li class="footernav list-inline-item"> <a class="footerimage" href="https://scholar.google.com/citations?user=XGqBCZAAAAAJ&hl=en" target="_blank" rel="noopner noreferrer">
							<i class="ai ai-google-scholar"></i></a>
						</li>
					</ul>
					<hr>
					<p class="colophon">&copy; <script>document.write( new Date().getFullYear() );</script> Sai Gautam Gopalakrishnan - Powered by <a class="off-note" href="https://jekyllrb.com" target="_blank" rel="noopener noreferrer">Jekyll</a> and adapted from <a class="off-note" href="https://bedford.io" target=+_blank" rel="noopener noreferrer">bedford.io</a>, with inputs from <a class="off-note" href="https://caneparesearch.org" target="_blank" rel="noopener noreferrer">PC</a>.
					</p>
				</div>
			</div>
		</div>
	</div>

	<!-- Jekyll Ideal Image Slider Include -->
<!-- https://github.com/jekylltools/jekyll-ideal-image-slider-include -->
<!-- v1.8 -->
</body>
</html>

